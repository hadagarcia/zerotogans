{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-tensor-operations.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hadagarcia/zerotogans/blob/main/notebooks/01_tensor_operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFY98zajN6cv"
      },
      "source": [
        "# Jovian Commit Essentials\n",
        "# Please retain and execute this cell without modifying the contents for `jovian.commit` to work\n",
        "!pip install jovian --upgrade -q\n",
        "import jovian\n",
        "jovian.utils.colab.set_colab_file_id('1zK1Aq0O-0YZjZkcHBADX3SuaOQ2L40pO')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWUt-N1t0d7Z"
      },
      "source": [
        "# PyTorch functions you need to know to work with tensors\n",
        "\n",
        "These are some common functions I've found on several NN PyTorch examples, even on personal experience I've seen this functions or similar ones implemented on Machine Learning and Deep Learning tutorials. \n",
        "\n",
        "- 1. torch.tensor\n",
        "- 2. torch.transpose\n",
        "- 3. torch.max\n",
        "- 4. torch.eq\n",
        "- 5. torch.unique\n",
        "- 6. Serialization, tensor.save / tensor.load"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAIcPKKlfzrd"
      },
      "source": [
        "Before we begin, let's install and import PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTXouqm50d7Z"
      },
      "source": [
        "# Import torch and other required modules\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31NMMPuj0d7Z"
      },
      "source": [
        "## **1. torch.tensor**\n",
        "\n",
        "A torch tensor is a multi-dimensional matrix containing elements of a single data type. Torch defines 10 tensor types, although a very used type is torch.float64\n",
        "\n",
        "There are many input options to construct a PyTorch tensor, mainly using the advantage of the NumPy bridge, making it very easy to use these arrays.\n",
        "\n",
        "---\n",
        "\n",
        "Syntaxis: \n",
        ">**torch.tensor**(*data(array_like)*) : Can be a list, tuple, NumPy ndarray, scalar and other types.\n",
        "\n",
        "Optional arguments:\n",
        "\n",
        "* dtype (torch.dtype)\n",
        "* device (torch.device)\n",
        "* requires_grad (bool)\n",
        "* pin_memory (bool)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMByn9W4Zx_i"
      },
      "source": [
        "#### 1.1 Simple NumPy array as input\n",
        "\n",
        "Two interesting parameters are *device* and *requires_grad*, where *device* is the main difference why we are not using NumPy arrays; it offers the possibility to allocate the Tensor on 'cpu' or 'cuda' devices, 'cuda' devices are usually GPUs allowing faster computations.\n",
        "\n",
        "*requires_grad* if True, it starts forming a backward graph that tracks every operation applied on it to calculate the gradients using something called a dynamic computation graph (DCG)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uo2iNAUaPej",
        "outputId": "a6500fbd-3b14-4291-c072-9bec03343be7"
      },
      "source": [
        "import numpy as np\n",
        "nArray = np.ones(5)\n",
        "print(nArray)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl54ERYXa32A",
        "outputId": "5f3ae66e-2b16-48dd-dda5-7b02d695b662"
      },
      "source": [
        "f1Tensor1 = torch.tensor(nArray, dtype=torch.float64, requires_grad=True)\n",
        "print(f1Tensor1)\n",
        "print(f1Tensor1.grad) # Gradients, in this case None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64, requires_grad=True)\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-Ye_Q-3bjRh"
      },
      "source": [
        "#### 1.2 Constructing a tensor using data from a CSV file.\n",
        "\n",
        "A real life example would be to get Data on CSV format, after applying some cleaning it can be used as input to construct a PyTorch Tensor as shown on this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjIPrTdO27Py"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "MYBOt6Gb3Jk-",
        "outputId": "4547b59a-f83b-453b-a8d3-41fbae2cb7aa"
      },
      "source": [
        "mockdata = pd.read_csv('MOCK_DATA.csv')\n",
        "sample = mockdata[['r', 'g', 'b']].sample(5) # Using a sample of 5 items, only for demonstration.\n",
        "sample"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>r</th>\n",
              "      <th>g</th>\n",
              "      <th>b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>75</td>\n",
              "      <td>62</td>\n",
              "      <td>186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>89</td>\n",
              "      <td>224</td>\n",
              "      <td>249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>78</td>\n",
              "      <td>185</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>151</td>\n",
              "      <td>70</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>32</td>\n",
              "      <td>198</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      r    g    b\n",
              "58   75   62  186\n",
              "42   89  224  249\n",
              "74   78  185  149\n",
              "3   151   70   89\n",
              "92   32  198   24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf6vS2lYkKTP",
        "outputId": "63b06caa-ce91-43ee-bdfa-eff87c10a42c"
      },
      "source": [
        "print(sample.values)\n",
        "print('Type: {} and shape: {}'.format(type(sample), sample.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 75  62 186]\n",
            " [ 89 224 249]\n",
            " [ 78 185 149]\n",
            " [151  70  89]\n",
            " [ 32 198  24]]\n",
            "Type: <class 'pandas.core.frame.DataFrame'> and shape: (5, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymWFu9sZ3ZGr",
        "outputId": "13d2e4d4-6466-4eca-d02f-d9ca46669407"
      },
      "source": [
        "# Our sample is a Pandas Dataframe, we need to convert it to a NumPy array\n",
        "tensorRGB = torch.tensor(sample.to_numpy())\n",
        "print(tensorRGB)\n",
        "print('Tensor type: {}'.format(type(tensorRGB)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 75,  62, 186],\n",
            "        [ 89, 224, 249],\n",
            "        [ 78, 185, 149],\n",
            "        [151,  70,  89],\n",
            "        [ 32, 198,  24]])\n",
            "Tensor type: <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh4HhJaykVb2"
      },
      "source": [
        "#### 1.3 [ Error: ValueError ] Not a valid Tensor\n",
        "\n",
        "The input should have a compatible shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbZKuN7n0d7b",
        "outputId": "defabb15-b928-46e8-c86b-abbd9b357cc3"
      },
      "source": [
        "torch.tensor([[1, 2], [3, 4, 5]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "expected sequence of length 2 at dim 1 (got 3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-28787d136593>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: expected sequence of length 2 at dim 1 (got 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJoLX9XI0d7b"
      },
      "source": [
        "## **2. torch.transpose**\n",
        "\n",
        "Sometimes is needed to swap the tensor dimensions, in order to do that we can use this function, which returns the transposed version.\n",
        "\n",
        "Using this function we can only transpose over 2D.\n",
        "\n",
        ">$A_{3,2} = \\begin{pmatrix} a_{1,1} & a_{1,2} \\\\  a_{2,1} & a_{2,2} \\\\ a_{3,1} & a_{3,2} \\end{pmatrix}$  --> $A_{2,3} = \\begin{pmatrix} a_{1,1} & a_{1,2} & a_{1,3} \\\\ a_{2,1} & a_{2,2} & a_{2,3} \\end{pmatrix}^T$\n",
        "\n",
        "---\n",
        "\n",
        "Syntaxis: \n",
        ">**torch.transpose**(*input(Tensor), dim0(int), dim1(int)*)\n",
        "\n",
        "Returns:\n",
        "\n",
        "*   output (Tensor): Transposed version of *input* \n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb9IYNWvVYUf"
      },
      "source": [
        "#### 2.1 Transposing a tensor of shape (2, 3)\n",
        "\n",
        "Following the rules to transpose a matrix, we'll obtain a tensor of shape (3, 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UIWs6X20d7b",
        "outputId": "4132ca01-9059-4774-9d95-42c794e0c823"
      },
      "source": [
        "simpleTensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "simpleTensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peaZYp-nsKhe",
        "outputId": "f69d9442-bdba-444f-e6d2-d24dc6a76436"
      },
      "source": [
        "f2Tensor1 = torch.transpose(simpleTensor, 0, 1)\n",
        "f2Tensor1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 4],\n",
              "        [2, 5],\n",
              "        [3, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwZEYMNM0d7b"
      },
      "source": [
        "#### 2.2 We'll transpose over 2D in a 3D Tensor\n",
        "\n",
        "By especifying the *dim0* and *dim1* parameters, we can define from which to which dimensions we need to transpose.\n",
        "\n",
        "In this case only the dimensions 1 to 2 will be transposed, passing from a shape (2, 5) to (5, 2). Dimension 0 remains the same. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPVU7HHU0d7b",
        "outputId": "09d85b8a-197f-49fb-c056-bdf2ef64adf6"
      },
      "source": [
        "# 3D Tensor (3, 2, 5)\n",
        "simpleTensor2 = torch.randn(3, 2, 5)\n",
        "print('Tensor 1 of shape (3, 2, 5): \\n{}\\n'.format(simpleTensor2))\n",
        "\n",
        "f2Tensor2 = torch.transpose(simpleTensor2, 1, 2)\n",
        "print('Tensor 2 of shape (3, 5, 2): \\n{}'.format(f2Tensor2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor 1 of shape (3, 2, 5): \n",
            "tensor([[[ 0.5390, -2.4411, -0.3869, -1.2065, -1.9151],\n",
            "         [-0.1402,  0.0821, -0.8802, -1.0765, -2.4328]],\n",
            "\n",
            "        [[-2.3460,  0.5511, -0.4033, -0.1044,  2.1832],\n",
            "         [ 1.0715,  1.2554, -0.4236, -1.0823, -0.3150]],\n",
            "\n",
            "        [[-0.4011, -0.6395, -0.2994,  0.7747,  0.0376],\n",
            "         [-1.4594, -1.6728, -0.3633,  0.6559, -0.2181]]])\n",
            "\n",
            "Tensor 2 of shape (3, 5, 2): \n",
            "tensor([[[ 0.5390, -0.1402],\n",
            "         [-2.4411,  0.0821],\n",
            "         [-0.3869, -0.8802],\n",
            "         [-1.2065, -1.0765],\n",
            "         [-1.9151, -2.4328]],\n",
            "\n",
            "        [[-2.3460,  1.0715],\n",
            "         [ 0.5511,  1.2554],\n",
            "         [-0.4033, -0.4236],\n",
            "         [-0.1044, -1.0823],\n",
            "         [ 2.1832, -0.3150]],\n",
            "\n",
            "        [[-0.4011, -1.4594],\n",
            "         [-0.6395, -1.6728],\n",
            "         [-0.2994, -0.3633],\n",
            "         [ 0.7747,  0.6559],\n",
            "         [ 0.0376, -0.2181]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6YhEgrD9qAO",
        "outputId": "51e174d2-d4e9-4987-fc4b-caa5f476bcd9"
      },
      "source": [
        "# If we need to transpose an N-Dimension Tensor, it's possible. We just need to use the function torch.Tensor.permute\n",
        "nDimTensor = torch.randn(2, 3, 5)\n",
        "print('nDimTensor {}: \\n{}\\n'.format(nDimTensor.size(), nDimTensor))\n",
        "\n",
        "permutedTensor = nDimTensor.permute(2, 0, 1)\n",
        "print('nDimTensor permuted {}: \\n{}'.format(permutedTensor.size() ,permutedTensor))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nDimTensor torch.Size([2, 3, 5]): \n",
            "tensor([[[-0.6859,  0.5925, -0.7868,  0.3200,  0.4541],\n",
            "         [ 0.9836,  2.1425,  1.1974, -0.8963, -0.0996],\n",
            "         [-0.1130,  0.3706,  0.1200, -2.0270,  0.1104]],\n",
            "\n",
            "        [[-0.6609,  0.8163, -0.8878,  0.7976,  1.3538],\n",
            "         [-1.4436,  1.3149,  0.2626,  0.1535, -1.2025],\n",
            "         [ 1.2259, -0.5591, -1.7703,  0.9217,  1.3029]]])\n",
            "\n",
            "nDimTensor permuted torch.Size([5, 2, 3]): \n",
            "tensor([[[-0.6859,  0.9836, -0.1130],\n",
            "         [-0.6609, -1.4436,  1.2259]],\n",
            "\n",
            "        [[ 0.5925,  2.1425,  0.3706],\n",
            "         [ 0.8163,  1.3149, -0.5591]],\n",
            "\n",
            "        [[-0.7868,  1.1974,  0.1200],\n",
            "         [-0.8878,  0.2626, -1.7703]],\n",
            "\n",
            "        [[ 0.3200, -0.8963, -2.0270],\n",
            "         [ 0.7976,  0.1535,  0.9217]],\n",
            "\n",
            "        [[ 0.4541, -0.0996,  0.1104],\n",
            "         [ 1.3538, -1.2025,  1.3029]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wG9vY6BO0d7b"
      },
      "source": [
        "#### 2.3 [ Error: TypeError ] It's required to specify the first and second dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "oEShB-aX0d7b",
        "outputId": "81fee0a0-ebe5-48fc-f259-d895f873d5c0"
      },
      "source": [
        "torch.transpose(torch.tensor([[1, 2, 3]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-66a906e7465f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: transpose() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, name dim0, name dim1)\n * (Tensor input, int dim0, int dim1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IkVhP8G0d7b"
      },
      "source": [
        "## **3. torch.max**\n",
        "\n",
        "Returns the maximum value of all elements for the input tensor given.\n",
        "\n",
        "If we use the second parameter, which is the dimension where we want to find the maximums, it returns a tuple (values, indices)\n",
        "\n",
        "---\n",
        "\n",
        "Syntaxis: \n",
        ">**torch.max**(*input(Tensor),  dim(int)*)\n",
        "\n",
        "Returns:\n",
        "\n",
        "*   output (tuple): two output tensors (max, max_indices) \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wstgKGfnTyOz"
      },
      "source": [
        "#### 3.1 Basic example with random values tensor\n",
        "\n",
        "Input is a tensor of 3 dimensions with random values and we'll look for the maximum value on the first dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw1geu-n0d7b",
        "outputId": "9c50a638-1fa3-4732-81b2-caadd2f2cafe"
      },
      "source": [
        "randomTensor = torch.randn(2, 3, 2)\n",
        "randomTensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.1600, -0.2537],\n",
              "         [-0.3126,  1.4879],\n",
              "         [-0.6872,  0.6803]],\n",
              "\n",
              "        [[-1.4099,  0.1844],\n",
              "         [ 1.9199, -0.1031],\n",
              "         [ 1.6564,  0.2365]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Scbtb7acP27c",
        "outputId": "b63e5d28-8907-4c91-d456-b392b04f7800"
      },
      "source": [
        "values, max_indices = torch.max(randomTensor, 0)\n",
        "print(values)\n",
        "print(max_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.1600,  0.1844],\n",
            "        [ 1.9199,  1.4879],\n",
            "        [ 1.6564,  0.6803]])\n",
            "tensor([[0, 1],\n",
            "        [1, 0],\n",
            "        [1, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjRRtj2I0d7b"
      },
      "source": [
        "#### 3.2 In this example, we're looking for the maximum on the second dimension.\n",
        "\n",
        "The max_indices output is a tensor with size [2], because the dimension we're evaluating is the second one.\n",
        "\n",
        "max_indices2 shows on which index was the maximum found."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAyoCLB90d7b",
        "outputId": "dc2e6619-febb-4c67-eeec-451a274720f1"
      },
      "source": [
        "randomTensor2 = torch.randn(2, 3)\n",
        "print(randomTensor2)\n",
        "\n",
        "values2, max_indices2 = torch.max(randomTensor2, 1)\n",
        "print('\\nMax values on each row: {}\\n'.format(values2))\n",
        "print('Indices where the max values were found on each row: \\n  row0 = row0[{}]\\n  row1 = row1[{}] \\n  {}'.format(max_indices2[0], max_indices2[1], max_indices2)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.1281, -0.6203, -0.8532],\n",
            "        [-0.8200, -0.8610,  0.6337]])\n",
            "\n",
            "Max values on each row: tensor([1.1281, 0.6337])\n",
            "\n",
            "Indices where the max values were found on each row: \n",
            "  row0 = row0[0]\n",
            "  row1 = row1[2] \n",
            "  tensor([0, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66b-xrCcNJMt",
        "outputId": "da5bfd62-e938-4b2a-9be8-b7c4650af08a"
      },
      "source": [
        "print(type(max_indices2))\n",
        "print(max_indices2.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YtBOeY80d7b"
      },
      "source": [
        "#### 3.3 [ Error: IndexError ] Wrong dimension given\n",
        "\n",
        "In this example we're asking to get the max over the second dimension, but the given input is a vector (one dimensional tensor)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "QNv1gZpi0d7b",
        "outputId": "415eb825-e81b-4711-fbcd-e0897ee2c7ea"
      },
      "source": [
        "torch.max(torch.randn(4), 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-147-39aeb276028c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT8C52vt0d7b"
      },
      "source": [
        "## **4. torch.eq**\n",
        "\n",
        "Compares two tensors element-wise. \n",
        "The second tensor should be a number or a tensor whose shape is *broadcastable* with the first one.\n",
        "\n",
        "> *broadcastable*: Broadcasting describes how tensors with different shapes are treated during arithmetic operations. Meaning the 2 tensors should be compatible in this case to be element-wise compared.\n",
        "\n",
        "---\n",
        "\n",
        "Syntaxis: \n",
        ">**torch.eq**(*input(Tensor), other(Tensor)*)\n",
        "\n",
        "Returns:\n",
        "\n",
        "*   output (Tensor): A boolean tensor with True values where *input* is equal to *other* and False elsewhere \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4DgohiieXvD"
      },
      "source": [
        "#### 4.1 Basic example\n",
        "\n",
        "We'll use two different tensors to compare using torch.eq, which in this case will return a tensor with booleans (3, 3).\n",
        "\n",
        "These tensors don't have the same shape, but they are broadcast compatible. If we broadcast compT1 to shape (3, 3) it looks like this:\n",
        "\n",
        "$\\begin{pmatrix} 1. & 1. & 1. \\end{pmatrix}$ --> $\\begin{pmatrix} 1. & 1. & 1. \\\\  1. & 1. & 1. \\\\ 1. & 1. & 1. \\end{pmatrix}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZdO7lJs0d7b",
        "outputId": "df396175-26de-4af1-df23-312001c98b92"
      },
      "source": [
        "compT1 = torch.ones(1, 3)\n",
        "compT2 = torch.eye(3, 3)\n",
        "print(compT1)\n",
        "print(compT2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.]])\n",
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYaDTGpRkeIF",
        "outputId": "172b54e3-50d0-4590-cd6b-564862f9153f"
      },
      "source": [
        "compT3 = torch.eq(compT1, compT2)\n",
        "print(compT3)\n",
        "\n",
        "# Another useful function is torch.all, which returns a final boolean\n",
        "torch.all(compT3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ True, False, False],\n",
            "        [False,  True, False],\n",
            "        [False, False,  True]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eK2eYYc0d7b"
      },
      "source": [
        "#### 4.2 Using our previous RGB Tensor obtained from the CSV file, we can compare using as the first input a tensor of shape (1, 3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSVq1OHb0d7c",
        "outputId": "35bc6d34-1dfe-4fa5-c3d4-248c6a4301d7"
      },
      "source": [
        "tensorRGB.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAPJV3iveng2",
        "outputId": "d998127b-8fa0-46e8-a9d4-299ee89adc70"
      },
      "source": [
        "# Let's look for the color white rgb(255, 255, 255)\n",
        "torch.eq(torch.tensor([255, 255, 255]), tensorRGB)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False, False],\n",
              "        [False, False, False],\n",
              "        [False, False, False],\n",
              "        [False, False, False],\n",
              "        [False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqgZsCZh0d7c"
      },
      "source": [
        "#### 4.3 [ Error: RuntimeError ] Tensors with none broadcastable shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "EN8Sq_wE0d7c",
        "outputId": "2270b018-019c-4895-d4d6-68175f3996a1"
      },
      "source": [
        "failTensor1 = torch.randn(2, 3)\n",
        "failTensor2 = torch.randn(3, 2)\n",
        "print('Size first tensor: {} \\nSize second tensor: {}'.format(failTensor1.shape, failTensor2.shape))\n",
        "\n",
        "torch.eq(failTensor1, failTensor2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size first tensor: torch.Size([2, 3]) \n",
            "Size second tensor: torch.Size([3, 2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-f7f4964e92a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Size first tensor: {} \\nSize second tensor: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailTensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfailTensor2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailTensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfailTensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaOdyvOD0d7c"
      },
      "source": [
        "## **5. torch.unique** \n",
        "\n",
        "It returns the unique elements of the input tensor.\n",
        "\n",
        "Sorting could be slow, so if your input tensor is already sorted, it's recommended to use **torch.unique_consecutive()** instead, which avoids the sorting.\n",
        "\n",
        "---\n",
        "\n",
        "Syntaxis: \n",
        ">**torch.unique**(*input(Tensor), sorted(bool), return_inverse(bool), return_counts(bool), dim(int)*)\n",
        "\n",
        "Returns:\n",
        "\n",
        "*   output (Tensor): The output list of unique scalar elements\n",
        "*   inverse_indices (Tensor): this is optional\n",
        "*   counts (Tensor): this is also optional\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3WAcsxYg5Sx"
      },
      "source": [
        "#### 5.1 Basic example\n",
        "\n",
        "First we'll use as input a tensor of shape (3, 3) with some repeated values, where the output will be a tensor with all unique values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXcO3Zsvg86o",
        "outputId": "e4cb2ae8-7d5b-4911-e49b-8a43529171f3"
      },
      "source": [
        "f5Tensor = torch.tensor([[1, 3, 2], [1, 0, 6], [0, 3, 0]])\n",
        "f5Tensor.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGUDUp-Epdi3",
        "outputId": "dbb3ea95-23a5-4cb5-ca1f-8fab3b6d112e"
      },
      "source": [
        "uTensor = torch.unique(f5Tensor)\n",
        "print('All unique elements: {}'.format(uTensor))\n",
        "uTensor.shape\n",
        "\n",
        "# We didn't specify over which dimension to look for uniques, so it went through all elements"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All unique elements: tensor([0, 1, 2, 3, 6])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9ErSB0JhJqU"
      },
      "source": [
        "#### 5.2 Using our previous RGB Tensor, we can find the unique colors we have for example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku5d5sxCnhvX",
        "outputId": "b09dd179-b174-47ba-ee34-647d1705df6f"
      },
      "source": [
        "# Since we don't have any duplicated colors, we'll concatenate a couple\n",
        "tensorRGB2 = torch.cat((torch.tensor([[151,  70,  89], [78, 185, 149]]), tensorRGB))\n",
        "tensorRGB2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[151,  70,  89],\n",
              "        [ 78, 185, 149],\n",
              "        [ 75,  62, 186],\n",
              "        [ 89, 224, 249],\n",
              "        [ 78, 185, 149],\n",
              "        [151,  70,  89],\n",
              "        [ 32, 198,  24]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XXNrM45hBQk",
        "outputId": "9267ca60-a62b-4afd-fa54-95ae20de536e"
      },
      "source": [
        "# Here is important to use dim=0, because we want to compare the colors [r, g, b] over the first dimension, \n",
        "# otherwise we'll compare every element, which is not the case.\n",
        "\n",
        "uniques, indices, counts = torch.unique(tensorRGB2, return_inverse=True, return_counts=True, dim=0)\n",
        "print('We can see there are {} unique colors'.format(len(uniques)))\n",
        "print(uniques)\n",
        "print('\\nInverse indices: \\n{}'.format(indices))\n",
        "print('\\nCounts: \\n{}'.format(counts))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We can see there are 5 unique colors\n",
            "tensor([[ 32, 198,  24],\n",
            "        [ 75,  62, 186],\n",
            "        [ 78, 185, 149],\n",
            "        [ 89, 224, 249],\n",
            "        [151,  70,  89]])\n",
            "\n",
            "Inverse indices: \n",
            "tensor([4, 2, 1, 3, 2, 4, 0])\n",
            "\n",
            "Counts: \n",
            "tensor([1, 1, 2, 1, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESPaZNVYhOPJ"
      },
      "source": [
        "#### 5.3 [ Error: ValueError ] If return_inverse=False, the inverse_indices are not returned"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "RI7KaXPThRZv",
        "outputId": "bcc803ce-7fc0-460e-f2d8-0a72f0066ee6"
      },
      "source": [
        "uniques, indices = torch.unique(torch.tensor([1, 2, 3, 3]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-b590b0f6b861>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j35QI4cI0d7b"
      },
      "source": [
        "## **6. Serialization, tensor.save / tensor.load**\n",
        "\n",
        "Saves an object to a disk file, E.g. a Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvdeagwIXCcL"
      },
      "source": [
        "#### 6.1 Basic example to save and load\n",
        "\n",
        "Here we'll save a tensor as 'tensor.pt' on the drive. A common PyTorch convention is to save tensors using .pt file extension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvqDH0220d7b"
      },
      "source": [
        "# Saving the tensor\n",
        "fileTensor = torch.tensor([0, 1, 2, 3, 4])\n",
        "torch.save(fileTensor, 'tensor.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-vG0Khj16jK",
        "outputId": "53ee7353-8156-4c94-f3a9-5ae2fac2cdcc"
      },
      "source": [
        "# Loading the tensor saved\n",
        "loadedTensor = torch.load('tensor.pt')\n",
        "print(loadedTensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s-l_VCf0d7b"
      },
      "source": [
        "#### 6.3 [ Error: FileNotFoundError ] The object does not exist or is not found"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "WEEq15Vk0d7b",
        "outputId": "4ff84ad5-d634-4c1b-b0f7-446b87a39b34"
      },
      "source": [
        "torch.load('noFile.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-148-3e8dcbcd9edf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'noFile.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'noFile.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-2iXrs10d7c"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Now that we have covered some useful functions to create tensors and perform mathematical operations with them, should not be so hard to keep analyzing some other similar functions. PyTorch offers many and it's worth it to look deeper.\n",
        "\n",
        "\n",
        "Next step would be to start analyzing **torch.nn** so we can move on with the main purpose of PyTorch, which is to provide libraries for Machine and Deep Learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO7jUMbV0d7c"
      },
      "source": [
        "## Reference Links\n",
        "Provide links to your references and other interesting articles about tensors\n",
        "* Official documentation for tensor operations: https://pytorch.org/docs/stable/torch.html\n",
        "* PyTorch Autograd: https://towardsdatascience.com/pytorch-autograd-understanding-the-heart-of-pytorchs-magic-2686cd94ec95\n",
        "* Matrix transpose: https://simple.wikipedia.org/wiki/Transpose#Examples\n",
        "* Use of torch.abs on Tensors: https://pennylane.ai/qml/demos/pytorch_noise.html\n",
        "* Broadcasting explained - Tensors for deep learning and neural networks: https://deeplizard.com/learn/video/6_33ulFDuCg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "eslKQx3g0d7c",
        "outputId": "aeb5ee31-4cdf-4c9d-8d4e-e7d7a5453569"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations', files=['MOCK_DATA.csv'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Uploading additional files...\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/hada-garcia/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/hada-garcia/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzjS99Wy0d7c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}